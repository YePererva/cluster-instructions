# Setting up the compute node
At this point, keep using the previous set-up and power up the node with template.

## 1. Setting up the shared folder

### (a) From dedicated storage under FreeNAS
Since it is mountable to the main node, it will be also mountable to compute node:

```
sudo mount 10.42.42.2:/mnt/clusterfs /storage/shared
cd /storage/shared
# We previously created folder at this location, now check if they are available
ls -l
# if yes: purge them
rm -rf ./*
```

If everything is OK, set-up the automount of shared folder on managing node via editing `/etc/fstab`:
```
10.42.42.2:/mnt/clusterfs    /storage/shared    nfs    auto,nofail,noatime,nolock,intr,tcp,actimeo=1800   0 0
```

### (b) Mounting the shared drive from management node [if used]

Test if remote folder is mountable:
```
sudo mount 10.42.42.1:/storage /storage
```
Check the permissions to write in it as:
```
# Usual way
for i in {1..10}; do mkdir /storage/TempFolder_$i; done
# If want to be fancy and get fixed length of folder name
for i in `seq -f "%03g" 1 10` ; do mkdir /storage/TempFolder_$i; done
```

If something gone wrong, go to main node and re-assign the permissions:
```
sudo mkdir /storage
sudo chown nobody.nogroup /storage
sudo chmod -R 777 /storage
```
After that - try again from computing node.
After success : add the mounting folder to `/etc/fstab`
```
10.42.42.1:/storage    /storage    nfs    auto,nofail,noatime,nolock,intr,tcp,actimeo=1800   0 0
```

**NB! :** For some reason, this set-up fails if computing node starts before managing node.
Re-connect doesn't work. Need to reboot computing node after the managing node is started. Alternatively, consider use crontab for periodical reconnect:
`sudo nano /etc/crontab` and add line:
```
*/5 * * * * root /bin/mount -a
```
This should re-mount all mounted shares every 5 minutes. May want to use `AutoFS` which will mount the share every time, when it is attempted to be accessed.

### Use of AutoFS [Not Tested]:
Edit file  `/etc/auto.master` and add the line:
```
/-  /etc/auto.mount
```
Edit or create file `/etc/auto.mount`:
```
/storage  -fstype=nfs,rw  10.42.42.1:/storage
# or  
/storage  -fstype=nfs,rw  10.42.42.2:/storage
```
Enable this service:
```
sudo systemctl enable --now autofs
```

## 2. Block the password authentication for `ssh`
This will allow communication between nodes with RSA keys only.

Edit file `/etc/ssh/sshd_config` and previously added line:
```
PasswordAuthentication yes
```
and change it to:
```
PasswordAuthentication no
```
Now, it can be accessed only with RSA generated previously and only from managing node!

## 3. Auto-start the SLURM on compute node
```
sudo systemctl enable slurmd
```

# 4. SLURM set-up

SLURM suggests to name nodes in manner of `{some name}{number}` (without curvy brackets), where:
- `some name`: can be any word or string
- `number`: any integer

In a manner of speaking, cluster is a city or street, where each node is a separate house with number. So, for a sake of example, lets use `kyiv` as a name.

## 4.1. On managing node

Set up the new name:
```
sudo hostnamectl set-hostname kyiv0
```

### Identify IP of attached compute node
Read MAC addresses of all computers attached to a certain interface (`eno1`):
```
sudo arp-scan --interface=enp2s2f1 --localnet
```
It will return all devices attached to the `enp2s2f1` interface according to subnet mask specified in `/etc/sysconfig/network-scripts/ifcfg-enp2s2f1`. The result should looks like:
```
Interface: enp2s2f1, type: EN10MB, MAC: 00:23:7d:5e:cf:2d, IPv4: 10.42.42.1
Starting arp-scan 1.9.7 with 256 hosts (https://github.com/royhills/arp-scan)
10.42.42.2      00:23:7d:5e:e1:9c       Hewlett Packard
10.42.42.238    00:23:7d:5e:e1:9a       Hewlett Packard

2 packets received by filter, 0 packets dropped by kernel
Ending arp-scan 1.9.7: 256 hosts scanned in 2.065 seconds (123.97 hosts/sec). 2 responded
```
Where `10.42.42.238` will be an IP address of attached compute node.

### Check if munge service is working:

From main node run:
```
munge -n | ssh 10.42.42.238 unmunge
```
and it should return something like:
```
STATUS:           Success (0)
ENCODE_HOST:      localhost (127.0.0.1)
ENCODE_TIME:      2020-09-18 17:25:03 -0400 (1600464303)
DECODE_TIME:      2020-09-18 17:25:05 -0400 (1600464305)
TTL:              300
CIPHER:           aes128 (4)
MAC:              sha256 (5)
ZIP:              none (0)
UID:              scientist (1000)
GID:              sudo (1000)
LENGTH:           0
```

### Collect info slurm-controller settings
Get the parameters of compute node via:
```
ssh 10.42.42.238 "slurmd -C"
```
It should return something like:
```
NodeName=localhost CPUs=8 Boards=1 SocketsPerBoard=2 CoresPerSocket=4 ThreadsPerCore=1 RealMemory=16028
UpTime=0-00:22:54
```
Keep it, but:
- without `UpTime` information
- decrease the amount of available RAM (for amount, used by OS for functioning)
- change the `NodeName` for `kyiv1`
- add IP address of compute node `NodeAddress=10.42.42.238`
```
NodeName=kyiv1 CPUs=8 Boards=1 SocketsPerBoard=2 CoresPerSocket=4 ThreadsPerCore=1 RealMemory=15028 NodeAddress=10.42.42.238
```

### Create / edit SLURM controller settings
Edit file `/etc/slurm/slurm.conf` on main node

Find lines with parameters `ControlMachine` and `ControlAddr`, and make them look as follow:
```
SlurmctldHost=kyiv0
SlurmctldAddr=10.42.42.1
```
Find line with parameter `ReturnToService` and change it as `ReturnToService=2`

Find lines with `SelectType` and `SelectTypeParameters` and replace those with:
```
SelectType=select/cons_res
SelectTypeParameters=CR_Core
```
Set the cluster name via editing the line with `ClusterName`:
```
ClusterName=kyiv_cluster
```

Now, go to the end of file, there should be something like:
```
# COMPUTE NODES
NodeName=localhost CPUs=1 State=UNKNOWN
PartitionName=debug Nodes=localhost Default=YES MaxTime=INFINITE State=UP
```
Change it to (according to previously collected information):
```
# COMPUTE NODES
NodeName=kyiv1 NodeAddr=10.42.42.238 CPUs=8 Boards=1 SocketsPerBoard=2 CoresPerSocket=4 ThreadsPerCore=1 RealMemory=15028
PartitionName=kyiv Nodes=kyiv[1] Default=YES MaxTime=INFINITE State=UP
```

**NB! :** Do not include the managing node to partition. Let it be a manager only! It is needed since it is ruling the DNS/DHCP/NFS and time servers.

Add ownership:
```
sudo chown slurm: /etc/slurm/slurm.conf
sudo touch /run/slurm/slurmctld.pid
sudo chown slurm: -R /run/slurm
sudo chown slurm: /run/slurm/slurmctld.pid
sudo mkdir /var/spool/slurmctld
sudo chown slurm: /var/spool/slurmctld
sudo chmod 755 /var/spool/slurmctld
sudo touch /var/log/slurmctld.log
sudo chown slurm: /var/log/slurmctld.log
sudo touch /var/log/slurm_jobacct.log /var/log/slurm_jobcomp.log
sudo chown slurm: /var/log/slurm_jobacct.log /var/log/slurm_jobcomp.log
```

```
sudo systemctl start slurmctld
sudo systemctl status slurmctld
slurmd -C
```

Copy config file to shared storage for easier later access from other nodes:
```
sudo cp /etc/slurm/slurm.conf /storage/shared/slurm.conf
```


**NB !:** If something goes wrong, there is an [issue](https://medium.com/p/c901786cba54/responses/show) on Slurm 18.08 and Rasbpian Stretch: you need to find and modify the line with `ProctrackType` value.
Originally it is `ProctrackType=proctrack/cgroup`
```
ProctrackType=proctrack/linuxproc
```

## 4.2. On the compute node
Change the name of node for `kyiv1`
```
sudo hostnamectl set-hostname kyiv1
```

```
sudo cp /storage/shared/slurm.conf /etc/slurm/slurm.conf
sudo chown slurm: /etc/slurm/slurm.conf
sudo mkdir /var/spool/slurmd
sudo chown slurm: /var/spool/slurmd
sudo chmod 755 /var/spool/slurmd
sudo touch /var/log/slurmd.log
sudo chown slurm: /var/log/slurmd.log
```

```
sudo systemctl start slurmd
sudo systemctl status slurmd
slurmd -C
scontrol ping
```
It should return `Slurmctld(primary) at kyiv0 is UP`.

**P.S. :** It may return `Slurmctld(primary) at kyiv0 is DOWN` if some settings with firewall are messed-up.
To check if the firewall is the reason, run `sudo systemctl stop firewalld` on the main node and try `scontrol ping` again.
If it returns `Slurmctld(primary) at kyiv0 is UP`, than there is the problem with firewall.
Check `firewalld` rules at `/etc/firewalld/direct.xml`

Restart firewall with `sudo systemctl start firewalld`.

In my case, the firewall issue was solved by:
```
sudo firewall-cmd --permanent --zone=trusted --add-source=10.42.42.0/24
sudo firewall-cmd --reload
```

##  Install software for computation
Now, install all software gonna be used for computation / modelling, etc.

In scope of this example, the cluster was purposed to perform some chemical and bioinformatical computation:
- [Gaussian 16](06.a._installation_of_Gaussian16.md), assuming you have a licence
- [Bioinformatics-related](06.b._installing_bioinformatics_tools.md)


## -1. Disabling the firewall on compute node

NOT recommended!

```
sudo systemctl disable firewalld
# or even remove it
sudo dnf remove -y firewalld
```

## Troubleshooting 1. Purge of mounted directory with numerous number of subfolders

If during mounting test procedure you created far too many objects, than you may encounter running the following code:
```
cd /storage
rm -rf ./*
```
The error could be:
```
-bash: /bin/rm: Argument list too long
```
The reason is well described [here](https://linuxconfig.org/bash-bin-rm-argument-list-too-long-solution) and [here](https://stackoverflow.com/questions/11289551/argument-list-too-long-error-for-rm-cp-mv-commands).

The solution to overcome it (but it will take morre time rather than `rm -rf /storage/*`):
```
cd /storage
for i in ./*; do rm -rf "$i"; done
# OR, if any progress indication is needed
for i in ./*; do echo "Removing $i ..."; rm -rf "$i"; done
```

---
[< PREVIOUS](05._setting_up_the_managing_node.md) | [NEXT >](07._multiplying_the_computing_nodes.md)
